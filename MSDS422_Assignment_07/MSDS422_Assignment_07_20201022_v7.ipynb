{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/djp840/MSDS_458_Public/blob/master/images/NorthwesternHeader.png?raw=1\">"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "DATE: October 22, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSDS422 Assignment 7\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>More Technical</b>: Throughout the notebook. This types of boxes provide more technical details and extra references about what you are seeing. They contain helpful tips, but you can safely skip them the first time you run through the code.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7v55rWlQehzL"
   },
   "source": [
    "#### Microsoft Research Data License Agreement for Kaggle Cats and Dogs Dataset<br>\n",
    "This Microsoft Research Data License Agreement (“Agreement”) is a legal agreement between you and Microsoft Corporation (or based on where you live, one of its affiliates). Please read them.  They apply to the Microsoft Research dataset named above, which may include any associated materials, text or speech files, associated media and “online” or electronic documentation and any updates we provide in our discretion (together, the “Dataset”). The terms also apply to any Microsoft (i) updates, (ii) supplements, (iii) internet-based services, and (iv) support services for this Dataset, unless other terms accompany those items. If so, those terms apply.\n",
    "By agreeing to this Agreement and/or by using the Dataset, you accept these terms. If you do not accept them, do not use the Dataset. If you comply with these terms, you have the rights below.<br><br>\n",
    "<b>SCOPE OF RIGHTS</b><br>\n",
    "You may only use the Dataset:<br>\n",
    "i. for non-commercial or research purposes only. Examples of non-commercial uses are teaching, academic research, public demonstrations and personal experimentation;<br>\n",
    "ii. for analyzing and testing purposes; and<br>\n",
    "iii. to publish (or present papers or articles) on your results from using such Dataset, provided that no material portion of the Dataset is included in any such publication or presentation.<br><br>\n",
    "<b>DISCLAIMER OF WARRANTY</b><br>\n",
    "The Dataset is licensed `as-is` You bear the risk of using it. Microsoft gives no express warranties, guarantees or conditions. You may have additional consumer rights or statutory guarantees under your local laws which this agreement cannot change. To the extent permitted under your local laws, Microsoft excludes the implied warranties of merchantability, fitness for a particular purpose and non-infringement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dn-6c02VmqiN"
   },
   "outputs": [],
   "source": [
    "# Helper libraries\n",
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import datetime\n",
    "from packaging import version\n",
    "import numpy as np\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.image import imread\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile\n",
    "#from plot_keras_history import plot_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify TensorFlow Version and Keras Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This notebook requires TensorFlow 2.0 or above\")\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Keras version: \", keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Suppress warning messages</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mount Google Drive to Colab Enviorment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>If the URL doesn't work:</b><br>https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765<br>\n",
    "Dataset = 786.68 MiB \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Cats vs Dogs Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "3sd9dQWa23aj",
    "outputId": "204992d5-90f4-4644-afa8-7a7e6cea757b"
   },
   "outputs": [],
   "source": [
    "!wget --no-check-certificate \\\n",
    "    \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\" \\\n",
    "    -O \"./data/cats-and-dogs.zip\"\n",
    "\n",
    "local_zip = './data/cats-and-dogs.zip'\n",
    "zip_ref   = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('./data')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "DM851ZmN28J3",
    "outputId": "228c28ed-89a4-4a78-c357-144694e3a8e3"
   },
   "outputs": [],
   "source": [
    "print(len(os.listdir('./data/PetImages/Cat/')))\n",
    "print(len(os.listdir('./data/PetImages/Dog/')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Expected Output:</b><br>\n",
    "12501 images Cat<br>\n",
    "12501 images Dog</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-QkLjxpmyK2"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('./data/cats_v_dogs')\n",
    "    os.mkdir('./data/cats_v_dogs/training')\n",
    "    os.mkdir('./data/cats_v_dogs/testing')\n",
    "    os.mkdir('./data/cats_v_dogs/training/cats')\n",
    "    os.mkdir('./data/cats_v_dogs/training/dogs')\n",
    "    os.mkdir('./data/cats_v_dogs/testing/cats')\n",
    "    os.mkdir('./data/cats_v_dogs/testing/dogs')\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "zvSODo0f9LaU",
    "outputId": "dc4e8d2f-466f-438f-cac8-4f4b3e548989"
   },
   "outputs": [],
   "source": [
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "    files = []\n",
    "    for filename in os.listdir(SOURCE):\n",
    "        file = SOURCE + filename\n",
    "        if os.path.getsize(file) > 0:\n",
    "            files.append(filename)\n",
    "        else:\n",
    "            print(filename + \" is zero length, so ignoring.\")\n",
    "\n",
    "    training_length = int(len(files) * SPLIT_SIZE)\n",
    "    testing_length = int(len(files) - training_length)\n",
    "    shuffled_set = random.sample(files, len(files))\n",
    "    training_set = shuffled_set[0:training_length]\n",
    "    testing_set = shuffled_set[-testing_length:]\n",
    "\n",
    "    for filename in training_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = TRAINING + filename\n",
    "        copyfile(this_file, destination)\n",
    "\n",
    "    for filename in testing_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = TESTING + filename\n",
    "        copyfile(this_file, destination)\n",
    "\n",
    "\n",
    "CAT_SOURCE_DIR = \"./data/PetImages/Cat/\"\n",
    "TRAINING_CATS_DIR = \"./data/cats_v_dogs/training/cats/\"\n",
    "TESTING_CATS_DIR = \"./data/cats_v_dogs/testing/cats/\"\n",
    "DOG_SOURCE_DIR = \"./data/PetImages/Dog/\"\n",
    "TRAINING_DOGS_DIR = \"./data/cats_v_dogs/training/dogs/\"\n",
    "TESTING_DOGS_DIR = \"./data/cats_v_dogs/testing/dogs/\"\n",
    "\n",
    "split_size = .9\n",
    "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
    "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Expected Output:</b><br>\n",
    "666.jpg is zero length, so ignoring<br>\n",
    "11702.jpg is zero length, so ignoring<br></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "hwHXFhVG3786",
    "outputId": "a3d742be-7365-4787-97a9-2599e688b222"
   },
   "outputs": [],
   "source": [
    "print(len(os.listdir('./data/cats_v_dogs/training/cats/')))\n",
    "print(len(os.listdir('./data/cats_v_dogs/training/dogs/')))\n",
    "print(len(os.listdir('./data/cats_v_dogs/testing/cats/')))\n",
    "print(len(os.listdir('./data/cats_v_dogs/testing/dogs/')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Expected output:</b><br>\n",
    "11250 - Training Cats<br>\n",
    "11250 - Training Dogs<br>\n",
    "1250 - Test Cats<br>\n",
    "1250 - Test Dogs<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cat Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15, 9))\n",
    "Catfolder = './data/PetImages/Cat/'\n",
    "for i in range(9):\n",
    "# define subplot\n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "# define filename\n",
    "    filename = Catfolder + str(i) + '.jpg'\n",
    "# load image pixels\n",
    "    image = imread(filename)\n",
    "# plot raw pixel data\n",
    "    pyplot.imshow(image)\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dog Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15, 9))\n",
    "Dogfolder = './data/PetImages/Dog/'\n",
    "for i in range(9):\n",
    "# define subplot\n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "# define filename\n",
    "    filename = Dogfolder + str(i) + '.jpg'\n",
    "# load image pixels\n",
    "    image = imread(filename)\n",
    "# plot raw pixel data\n",
    "    pyplot.imshow(image)\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-BQrav4anTmj"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(448, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, \"MCVD_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to setting up our model architecture, we also need to define which algorithm should the model use in order to optimize the weights and biases as per the given data. We will use stochastic gradient descent.\n",
    "\n",
    "We also need to define a loss function. Think of this function as the difference between the predicted outputs and the actual outputs given in the dataset. This loss needs to be minimised in order to have a higher model accuracy. That's what the optimization algorithm essentially does - it minimises the loss during model training. For our multi-class classification problem, categorical cross entropy is commonly used.\n",
    "\n",
    "Finally, we will use the accuracy during training as a metric to keep track of as the model trains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer that implements the Adam algorithm\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam</div>\n",
    "\n",
    "Adam optimization is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments<br>\n",
    "According to Kingma et al., 2014, the method is \"computationally efficient, has little memory requirement, invariant to diagonal rescaling of gradients, and is well suited for problems that are large in terms of data/parameters\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>tf.keras.preprocessing.image.ImageDataGenerator</b><br>\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator</div><br>\n",
    "A DataFrame Iterator yielding tuples of (x, y) where x is a numpy array containing a batch of images with shape (batch_size, *target_size, channels) and y is a numpy array of corresponding labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fQrZfVgz4j2g"
   },
   "outputs": [],
   "source": [
    "TRAINING_DIR = \"./data/cats_v_dogs/training/\"\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                    batch_size=250,\n",
    "                                                    class_mode='binary',\n",
    "                                                    target_size=(150, 150))\n",
    "\n",
    "VALIDATION_DIR = \"./data/cats_v_dogs/testing/\"\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
    "                                                              batch_size=250,\n",
    "                                                              class_mode='binary',\n",
    "                                                              target_size=(150, 150))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Expected Output:</b><br>\n",
    "Found 22498 images belonging to 2 classes<br>\n",
    "Found 2500 images belonging to 2 classes<br></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow From Directory "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>flow_from_directory - Default Parameters</b><br>\n",
    "    flow_from_directory(<br>\n",
    "    directory, target_size=(256, 256), color_mode='rgb', classes=None,\n",
    "    class_mode='categorical', batch_size=32, shuffle=True, seed=None,\n",
    "    save_to_dir=None, save_prefix='', save_format='png', follow_links=False,\n",
    "    subset=None, interpolation='nearest'<br>\n",
    ")<br>\n",
    "\n",
    "Takes the path to a directory & generates batches of augmented data</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5qE1G6JB4fMn"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, epochs=10\n",
    "                    ,validation_data=validation_generator\n",
    "                    ,validation_steps=6\n",
    "                    #,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=2)]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_history(history.history)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Performance Metrics \n",
    "\n",
    "We use Matplotlib to create 2 plots--displaying the training and validation loss (resp. accuracy) for each (training) epoch side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, len(acc) + 1), history.history['acc'], label = 'Training')\n",
    "plt.plot(range(1, len(val_acc) + 1), history.history['val_acc'], label = 'Validation')\n",
    "plt.ylim([0.7, 1.0])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, len(loss) + 1), history.history['loss'], label = 'Training')\n",
    "plt.plot(range(1, len(val_loss) + 1), history.history['val_loss'], label = 'Validation')\n",
    "plt.ylim([0.0, 0.5])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(validation_generator, validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('shape of preds: ', predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A prediction is an array of numbers. They represent the model's \"confidence\" that the image corresponds to each of the 2 different classes of pets (Cats or Dogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfImageNames = [\"./data/PetImages/Cat/2021.jpg\"]\n",
    "for imageName in listOfImageNames:\n",
    "    display(Image(filename=imageName))\n",
    "    print(imageName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfImageNames = [\"./data/PetImages/Dog/2020.jpg\"]\n",
    "for imageName in listOfImageNames:\n",
    "    display(Image(filename=imageName))\n",
    "    print(imageName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[2020]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lab6-Cats-v-Dogs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
